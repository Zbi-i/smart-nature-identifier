import torch
from torchvision import models, transforms
from flask import Flask, request, jsonify
from flask_cors import CORS
from PIL import Image
import io
import json
import os
from dotenv import load_dotenv
import requests
import re
import base64
import traceback
import asyncio;
import edge_tts;
import cn2an
from ddgs import DDGS

app = Flask(__name__)
CORS(app)

# --- 1. ResNet-101 + GPU é…ç½® ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"æ£€æµ‹åˆ°ç¡¬ä»¶åŠ é€Ÿ: {device}")
model = models.resnet101(weights='DEFAULT').to(device)
model.eval()
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
with open('labels.json', 'r') as f:
    labels = json.load(f)
print("æ¨¡å‹åŠ è½½å®Œæ¯•ã€‚")

load_dotenv()
BAIDU_API_KEY = os.getenv("BAIDU_API_KEY")
BAIDU_SECRET_KEY = os.getenv("BAIDU_SECRET_KEY")
UNSPLASH_ACCESS_KEY = os.getenv("UNSPLASH_ACCESS_KEY")
PIXABAY_API_KEY = os.getenv("PIXABAY_API_KEY")
LLM_API_KEY = os.getenv("LLM_API_KEY")
LLM_API_URL = os.getenv("LLM_API_URL")

def get_baidu_token():
    url = f"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={BAIDU_API_KEY}&client_secret={BAIDU_SECRET_KEY}"
    res = requests.post(url).json()
    return res.get("access_token")

def baidu_identify(image_bytes):
    print(">>> æœ¬åœ°è¯†åˆ«åº¦ä½ï¼Œæ­£åœ¨è¯·æ±‚äº‘ç«¯å¢å¼ºè¯†åˆ«...")
    base64_img = base64.b64encode(image_bytes).decode('utf-8')
    token = get_baidu_token()
    url = f"https://aip.baidubce.com/rest/2.0/image-classify/v2/advanced_general?access_token={token}"
    res = requests.post(url, data={'image': base64_img}, headers={'Content-Type': 'application/x-www-form-urlencoded'}).json()
    if res.get('result'):
        top = res['result'][0]
        return top['keyword'], top['score'], "äº‘ç«¯å¢å¼º(ç™¾åº¦AI)"
    return None, 0, "è¯†åˆ«å¤±è´¥"

# --- 3. è¯†åˆ«æ¥å£ ---
@app.route('/api/identify', methods=['POST'])
def identify():
    if 'image' not in request.files:
        return jsonify({'success': False, 'message': 'No image'}), 400
    file = request.files['image']
    img_bytes = file.read()
    try:
        img = Image.open(io.BytesIO(img_bytes)).convert('RGB')
        img_tensor = preprocess(img).unsqueeze(0).to(device)
        with torch.no_grad():
            outputs = model(img_tensor)
        probs = torch.nn.functional.softmax(outputs[0], dim=0)
        score, idx = torch.max(probs, 0)
        local_name = labels[idx.item()]
        local_score = score.item()
        if local_score < 0.60:
            cloud_name, cloud_score, source = baidu_identify(img_bytes)
            if cloud_name:
                return jsonify({'success': True, 'name': cloud_name, 'score': cloud_score, 'source': source})
        return jsonify({'success': True, 'name': local_name, 'score': local_score, 'source': "æœ¬åœ°é«˜ç²¾åº¦æ¨¡å‹(ResNet-101)"})
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)}), 500

# --- 4. å‡çº§ç‰ˆ â€œæ¢ç´¢å‘ç°â€ æ¥å£ (Pixabay ç‰ˆ) ---
@app.route('/api/recommendations', methods=['GET'])
def get_recommendations():
    try:
        # 1. è°ƒç”¨å¤§æ¨¡å‹è·å–åç§° (ä¿æŒä¹‹å‰çš„ä¸­è‹±åŒè¯­ Prompt)
        print("æ­¥éª¤1: è°ƒç”¨å¤§æ¨¡å‹è·å–æ¨è...")
        llm_prompt = {
            "model": "deepseek-v3-2-251201",
            "messages": [{
                "role": "user", 
                "content": "è¯·éšæœºç”Ÿæˆ3ä¸ªåŠ¨æ¤ç‰©åç§°ã€‚æŒ‰JSONè¿”å›ï¼š{\"recommendations\": [{\"cn\":\"\", \"en\":\"\"}, ...]}"
            }],
            "stream": False
        }
        headers = {'Content-Type': 'application/json', 'Authorization': f'Bearer {LLM_API_KEY}'}
        response = requests.post(LLM_API_URL, json=llm_prompt, headers=headers)
        
        content_str = response.json()['choices'][0]['message']['content']
        json_match = re.search(r'\{.*\}', content_str, re.DOTALL)
        if json_match: content_str = json_match.group(0)
        
        items = json.loads(content_str)['recommendations']
        print(f"è·å–åç§°æˆåŠŸ: {items}")

        # 2. è°ƒç”¨ Pixabay è·å–å›¾ç‰‡
        print("æ­¥éª¤2: å¼€å§‹ä» Pixabay è·å–é«˜è´¨å›¾ç‰‡...")
        recommendations_with_images = []
        
        for item in items:
            cn_name = item['cn']
            en_name = item['en']
            
            try:
                # ğŸŒŸ è°ƒç”¨ Pixabay API
                # q: æœç´¢å…³é”®è¯, image_type: åªè¦ç…§ç‰‡, safesearch: å¼€å¯å®‰å…¨æœç´¢
                pix_url = f"https://pixabay.com/api/?key={PIXABAY_API_KEY}&q={en_name.replace(' ', '+')}&image_type=photo&safesearch=true&per_page=3"
                
                pix_res = requests.get(pix_url, timeout=5).json()
                
                if pix_res.get('hits') and len(pix_res['hits']) > 0:
                    # å–ç¬¬ä¸€å¼ æœ€ç›¸å…³çš„å›¾ç‰‡ï¼Œä½¿ç”¨ webformatURL (å°ºå¯¸é€‚ä¸­)
                    img_url = pix_res['hits'][0]['webformatURL']
                    recommendations_with_images.append({'name': cn_name, 'imageUrl': img_url})
                    print(f"Pixabay æˆåŠŸ: {cn_name} -> {img_url}")
                else:
                    raise Exception("Pixabay no results")
                    
            except Exception as e:
                print(f"Pixabay æœç´¢ {cn_name} å¤±è´¥: {e}ï¼Œä½¿ç”¨ç»ˆæå¤‡ç”¨å›¾")
                # ğŸŒŸ ç»ˆæå…œåº•ï¼šå¦‚æœ API åäº†ï¼Œç›´æ¥ç»™ä¸€ä¸ª Unsplash çš„å›¾ç‰‡é“¾æ¥ï¼Œè®©å‰ç«¯å»é‡å®šå‘
                # è¿™ä¸ªé“¾æ¥å‡ ä¹ 100% èƒ½ç”Ÿæˆå‡ºå›¾ç‰‡
                fallback_url = f"https://images.unsplash.com/photo-1470071459604-3b5ec3a7fe05?fit=crop&w=500&q=80"
                recommendations_with_images.append({'name': cn_name, 'imageUrl': fallback_url})
        
        return jsonify({'success': True, 'data': recommendations_with_images})

    except Exception as e:
        traceback.print_exc()
        return jsonify({'success': False, 'message': 'æ¨èæ¨¡å—æš‚æ—¶ç»´æŠ¤ä¸­'}), 500

# --- 5. TTS æ¥å£ ---
@app.route('/api/tts', methods=['POST'])
def tts_generate():
    data = request.json
    text = data.get('text', '')
    
    if not text:
        return jsonify({'success': False, 'message': 'No text'}), 400

    # -----------------------------------------------------------
    # ğŸŒŸ ç¬¬ä¸€æ­¥ï¼šä¼˜å…ˆå¤„ç†æ•°å­—èŒƒå›´
    # -----------------------------------------------------------
    try:
        # å°† "2-5" æ›¿æ¢ä¸º "2 åˆ° 5" (åŠ ç©ºæ ¼æœ‰åŠ©äºè¯­éŸ³åœé¡¿å’Œè½¬æ¢å‡†ç¡®æ€§)
        text = re.sub(r'(\d+)\s*[-~]\s*(\d+)', r'\1 åˆ° \2', text)
    except Exception:
        pass

    # -----------------------------------------------------------
    # ğŸŒŸ ç¬¬äºŒæ­¥ï¼šæ¸…æ´— Markdown å’Œ è¡¨æƒ…
    # -----------------------------------------------------------
    # 1. ç§»é™¤ Markdown ç¬¦å· (*, #, >, `) - ä¸ç§»é™¤å‡å·
    clean_text = re.sub(r'[*#>`]', '', text)
    
    # # 2. ç§»é™¤ Emoji
    # æ³¨æ„ï¼šè¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼è¦†ç›–äº†å¤§éƒ¨åˆ†å¸¸è§çš„ Emojiï¼Œä½†ä¼šæ›¿æ¢æ‰æ•°å­—æš‚ä¸ä½¿ç”¨
    # emoji_pattern = re.compile(
    #     "["
    #     "\U00010000-\U0010ffff"
    #     "\u2600-\u27bf"
    #     "\u1f300-\u1f64f"c
    #     "\u1f680-\u1f6ff"
    #     "]+", flags=re.UNICODE)
    # clean_text = emoji_pattern.sub('', clean_text)
    
    # 3. ç§»é™¤å¤šä½™ç©ºç™½
    clean_text = clean_text.replace('\n', ' ').strip()

    # -----------------------------------------------------------
    # ğŸŒŸ ç¬¬ä¸‰æ­¥ï¼šæ•°å­—è½¬ä¸­æ–‡ (cn2an)
    # -----------------------------------------------------------
    try:
        clean_text = cn2an.transform(clean_text, "an2cn")
    except Exception as e:
        print(f"æ•°å­—è½¬æ¢å¿½ç•¥: {e}")

    # -----------------------------------------------------------
    # ğŸŒŸ ç¬¬å››æ­¥ï¼šç”ŸæˆéŸ³é¢‘
    # -----------------------------------------------------------
    print(f"TTSæ–‡æœ¬: {clean_text[:60]}...") # æ‰“å°æ—¥å¿—æ£€æŸ¥ä¸€ä¸‹

    VOICE = "zh-CN-XiaoxiaoNeural"
    OUTPUT_FILE = "tts_output.mp3"

    async def _run_tts():
        communicate = edge_tts.Communicate(clean_text, VOICE)
        await communicate.save(OUTPUT_FILE)

    try:
        asyncio.run(_run_tts())
        with open(OUTPUT_FILE, "rb") as audio:
            audio_data = audio.read()
        return base64.b64encode(audio_data).decode('utf-8')
    except Exception as e:
        print(f"TTS Error: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)